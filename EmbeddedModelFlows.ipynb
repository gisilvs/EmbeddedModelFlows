{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EmbeddedModelFlows.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmW56G7thNLu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is a demonstration on how to define and use a gated Embedded-Model flow on the time series datasets with either continuity or smoothness structures. The implementation for all the experiments can be found in the public repo, which is currently under refactoring for official release."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq7QCaLkrx2e",
        "outputId": "4da548df-553b-42da-e091-489bdc175300"
      },
      "source": [
        "!pip install tf-nightly tfp-nightly"
      ],
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.7/dist-packages (2.8.0.dev20211107)\n",
            "Requirement already satisfied: tfp-nightly in /usr/local/lib/python3.7/dist-packages (0.15.0.dev20211107)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.8.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.8.0.dev2021110708)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (12.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: tb-nightly~=2.8.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.8.0a20211106)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.41.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.21.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: keras-nightly~=2.8.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.8.0.dev2021110808)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.8.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.8.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.8.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.8.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.8.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.8.0.a->tf-nightly) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.8.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.8.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.8.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.8.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.8.0.a->tf-nightly) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.8.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tfp-nightly) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tfp-nightly) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tfp-nightly) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.8.0.a->tf-nightly) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBG-Vl7nsY6M"
      },
      "source": [
        "import functools\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability.python.internal import prefer_static as ps\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "tfk = tf.keras\n",
        "tfkl = tfk.layers\n",
        "Root = tfd.JointDistributionCoroutine.Root"
      ],
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHa_ngRoboTA"
      },
      "source": [
        "# Gated EMF\n",
        "In the following code blocks there is an implementation fo the Gated EMF bijector. For the non gated case, with most distributions it is possible to create the EMF bijector by first defining a structure as a `JointDistributionCoroutine` as we will see later, and then using \n",
        "\n",
        "```bijector = tfe.bijectors.make_distribution_bijector(structure)```\n",
        "\n",
        "The way to build the gated version is still in the development phase, and for now works by first initializing a (global) dict containing the gating parameters, one for each variable. \n",
        "\n",
        "We then define a bijector class to turn Normal distributions into gated bijectors (a more generic version is available in the file `gate_bijector.py`.\n",
        "Finally, the GatedAutoFromNormal class allows us to turn any `JointDistributionCoroutine` into a gated bijector. Note that we have to manually define the bijective transformations in the dict `gated_stdnormal_bijector_fns`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EspQB_mb_Qc_"
      },
      "source": [
        "# Global dict (DANGEROUS)\n",
        "residual_fraction_vars = {}\n",
        "\n",
        "def get_residual_fraction(dist):\n",
        "  dist_name = dist.parameters['name']\n",
        "  if dist_name not in residual_fraction_vars:\n",
        "    bij = tfb.Chain([tfb.Sigmoid(), tfb.Scale(100)])\n",
        "    residual_fraction_vars[dist_name] = tfp.util.TransformedVariable(0.999,\n",
        "                                                                     bijector=bij,\n",
        "                                                                     name=f'residual_fraction')   \n",
        "  return residual_fraction_vars[dist_name]"
      ],
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOxGvMTiuj7T"
      },
      "source": [
        "class GateBijectorForNormal(tfb.Bijector):\n",
        "\n",
        "  def __init__(self, loc, scale, residual_fraction, validate_args=False,\n",
        "               name='gate_bijector_for_normal'):\n",
        "    self.loc = loc\n",
        "    self.scale = scale\n",
        "    self.residual_fraction = residual_fraction\n",
        "    super(GateBijectorForNormal, self).__init__(\n",
        "      validate_args=validate_args,\n",
        "      forward_min_event_ndims=0,\n",
        "      name=name)\n",
        "\n",
        "  def _forward(self, x):\n",
        "    x = self.residual_fraction * (self.loc + self.scale * x) + \\\n",
        "        (1 - self.residual_fraction) * x\n",
        "    return x\n",
        "\n",
        "  def _inverse(self, y):\n",
        "    y = (y - self.residual_fraction * self.loc) / (\n",
        "          self.residual_fraction * self.scale + 1 - self.residual_fraction)\n",
        "    return y\n",
        "\n",
        "  def _forward_log_det_jacobian(self, x):\n",
        "    fldj = tf.math.log(\n",
        "      self.residual_fraction * (self.scale-1) + 1)\n",
        "    return fldj"
      ],
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPnZ04jMvAmJ"
      },
      "source": [
        "gated_stdnormal_bijector_fns = {\n",
        "  tfd.Gamma: lambda d: tfd.ApproxGammaFromNormal(d.concentration,\n",
        "                                                 d._rate_parameter()),\n",
        "  # using specific bijector for normal, use next line for generic one\n",
        "  tfd.Normal: lambda d: GateBijectorForNormal(d.loc, d.scale, get_residual_fraction(d)),\n",
        "  # tfd.Normal: lambda d: GateBijector(tfb.Shift(d.loc)(tfb.Scale(d.scale)),\n",
        "                                     # get_residual_fraction(d)),\n",
        "  tfd.HalfNormal: lambda d: GateBijector(tfb.Softplus()(tfb.Scale(d.scale)),\n",
        "                                         get_residual_fraction(d)),\n",
        "  tfd.MultivariateNormalDiag: lambda d: GateBijector(\n",
        "    tfb.Shift(d.loc)(tfb.Scale(d.scale)), get_residual_fraction(d)),\n",
        "  tfd.MultivariateNormalTriL: lambda d: GateBijector(tfb.Shift(d.loc)(\n",
        "    tfb.ScaleTriL(d.scale_tril)), get_residual_fraction(d)),\n",
        "  tfd.TransformedDistribution: lambda d: d.bijector(\n",
        "    _gated_bijector_from_stdnormal(d.distribution)),\n",
        "  tfd.Uniform: lambda d: GateBijector(tfb.Shift(d.low)(\n",
        "    tfb.Scale(d.high - d.low)(tfb.NormalCDF())), get_residual_fraction(d)),\n",
        "  tfd.Sample: lambda d: _gated_bijector_from_stdnormal_sample(d.distribution),\n",
        "  tfd.Independent: lambda d: _gated_bijector_from_stdnormal(d.distribution),\n",
        "  tfd.MixtureSameFamily: lambda d: GateBijector(tfb.Chain([InverseMixtureOfGaussians(d), tfb.NormalCDF()]), get_residual_fraction(d))\n",
        "}\n",
        "\n",
        "def _gated_bijector_from_stdnormal(dist):\n",
        "  fn = gated_stdnormal_bijector_fns[type(dist)]\n",
        "  return fn(dist)\n",
        "\n",
        "class GatedAutoFromNormal(tfd.joint_distribution._DefaultJointBijector):\n",
        "\n",
        "  def __init__(self, dist):\n",
        "    return super().__init__(dist, bijector_fn=_gated_bijector_from_stdnormal)"
      ],
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXyOnufze0-_"
      },
      "source": [
        "# Flows funcitons\n",
        "\n",
        "In the following blocks we define a few functions to get Masked Autoregressive Flows (or their inverse, Inverse Autoregressive Flows) and Gated EMF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5CEd1NtuM54"
      },
      "source": [
        "def build_iaf_bijector(num_hidden_units,\n",
        "                       ndims,\n",
        "                       activation_fn,\n",
        "                       dtype,\n",
        "                       num_flow_layers=2, is_iaf=True):\n",
        "  make_swap = lambda: tfb.Permute(ps.range(ndims - 1, -1, -1))\n",
        "\n",
        "  def make_maf():\n",
        "    net = tfb.AutoregressiveNetwork(\n",
        "      2,\n",
        "      hidden_units=[num_hidden_units, num_hidden_units],\n",
        "      activation=activation_fn,\n",
        "      dtype=dtype)\n",
        "\n",
        "    maf = tfb.MaskedAutoregressiveFlow(\n",
        "      bijector_fn=lambda x: tfb.Chain(\n",
        "        [tfb.Shift(net(x)[Ellipsis, 0]),  # pylint: disable=g-long-lambda\n",
        "         tfb.Scale(log_scale=net(x)[Ellipsis, 1])]))\n",
        "\n",
        "    if is_iaf:\n",
        "      maf = tfb.Invert(maf)\n",
        "    # To track the variables\n",
        "    maf._net = net  # pylint: disable=protected-access\n",
        "    return maf\n",
        "\n",
        "  iaf_bijector = [make_maf()]\n",
        "  '''if not is_iaf:\n",
        "    iaf_bijector.append(tfb.BatchNormalization())'''\n",
        "  for _ in range(num_flow_layers - 1):\n",
        "    iaf_bijector.extend([make_swap(), make_maf()])\n",
        "    '''if not is_iaf:\n",
        "      iaf_bijector.append(tfb.BatchNormalization())'''\n",
        "\n",
        "  return iaf_bijector"
      ],
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpHZb-ervQxa"
      },
      "source": [
        "'''used to get some useful info about the input structure'''\n",
        "def get_prior_matching_bijectors_and_event_dims(prior):\n",
        "  event_shape = prior.event_shape_tensor()\n",
        "  flat_event_shape = tf.nest.flatten(event_shape)\n",
        "  flat_event_size = tf.nest.map_structure(tf.reduce_prod, flat_event_shape)\n",
        "  try:\n",
        "    event_space_bijector = prior.experimental_default_event_space_bijector()\n",
        "  except:\n",
        "    event_space_bijector = None\n",
        "\n",
        "  split_bijector = tfb.Split(flat_event_size)\n",
        "  unflatten_bijector = tfb.Restructure(\n",
        "    tf.nest.pack_sequence_as(\n",
        "      event_shape, range(len(flat_event_shape))))\n",
        "  reshape_bijector = tfb.JointMap(\n",
        "    tf.nest.map_structure(tfb.Reshape, flat_event_shape,\n",
        "                          [x[tf.newaxis] for x in flat_event_size]))\n",
        "\n",
        "  if event_space_bijector:\n",
        "\n",
        "    prior_matching_bijectors = [event_space_bijector, unflatten_bijector,\n",
        "                                reshape_bijector, split_bijector]\n",
        "\n",
        "  else:\n",
        "    prior_matching_bijectors = [unflatten_bijector,\n",
        "                                reshape_bijector, split_bijector]\n",
        "\n",
        "  dtype = tf.nest.flatten(prior.dtype)[0]\n",
        "\n",
        "  return event_shape, flat_event_shape, flat_event_size, int(\n",
        "    tf.reduce_sum(flat_event_size)), dtype, prior_matching_bijectors\n"
      ],
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGr1rvEPwBj6"
      },
      "source": [
        "def get_maf(structure, flow_params={}):\n",
        "  event_shape, flat_event_shape, flat_event_size, ndims, dtype, prior_matching_bijectors = get_prior_matching_bijectors_and_event_dims(\n",
        "    structure)\n",
        "\n",
        "  base_distribution = tfd.Sample(\n",
        "    tfd.Normal(tf.zeros([], dtype=dtype), 1.), sample_shape=[ndims])\n",
        "  if 'num_flow_layers' not in flow_params:\n",
        "    flow_params['num_flow_layers'] = 2\n",
        "  if 'num_hidden_units' not in flow_params:\n",
        "    flow_params['num_hidden_units'] = 512\n",
        "  if 'activation_fn' not in flow_params:\n",
        "    flow_params['activation_fn'] = tf.math.tanh\n",
        "  flow_params['dtype'] = dtype\n",
        "  flow_params['ndims'] = ndims\n",
        "  flow_params['is_iaf'] = False\n",
        "  flow_bijector = build_iaf_bijector(**flow_params)\n",
        "\n",
        "  nf_surrogate_posterior = tfd.TransformedDistribution(\n",
        "    base_distribution,\n",
        "    bijector=tfb.Chain(prior_matching_bijectors +\n",
        "                       flow_bijector\n",
        "                       ))\n",
        "\n",
        "  return nf_surrogate_posterior"
      ],
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JobbbiBwbDC"
      },
      "source": [
        "def get_gated_emf_t(prior_structure, flow_params={}):\n",
        "  residual_fraction_vars = {}\n",
        "  flow_params['activation_fn'] = tf.nn.relu\n",
        "  backbone_flow = get_maf(structure=prior_structure, flow_params=flow_params)\n",
        "  bijector = GatedAutoFromNormal(prior_structure)\n",
        "  return tfd.TransformedDistribution(\n",
        "    distribution=backbone_flow,\n",
        "    bijector=bijector\n",
        "  )"
      ],
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dDinItOfYhq"
      },
      "source": [
        "# Training functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S065mnnHf11U"
      },
      "source": [
        "In `build_model` we can initialize a new model. We can choose between MAF with two autoregressive layers (maf), MAF with three autoregressive layers (maf3) and gated EMF with structured bijector on top (gated_emf_t). We also specify the induced structures, continuity or smoothness. Finally, we define the toy datasets as generators, for Brownian Motion, Lorenz System and Ornstein-Uhlenbeck process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAAmYYitKcj"
      },
      "source": [
        "@tf.function\n",
        "def optimizer_step(net, inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -net.log_prob(inputs)\n",
        "  grads = tape.gradient(loss, net.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, net.trainable_variables))\n",
        "  return loss"
      ],
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skEFJq5tjuQ"
      },
      "source": [
        "def build_model(model_name, time_step_dim, series_len, structure):\n",
        "    if model_name=='maf' or model_name == 'maf3':\n",
        "      scales = tf.ones(time_step_dim)\n",
        "    else:\n",
        "      scales = tfp.util.TransformedVariable(tf.ones(time_step_dim), tfb.Softplus())\n",
        "    initial_mean = tf.zeros(time_step_dim)\n",
        "\n",
        "    if structure == 'continuity':\n",
        "      @tfd.JointDistributionCoroutine\n",
        "      def prior_structure():\n",
        "        new = yield Root(tfd.Independent(tfd.Normal(loc=initial_mean,\n",
        "                                    scale=tf.ones_like(initial_mean), name='prior0'),1))\n",
        "\n",
        "        for t in range(1, series_len):\n",
        "          new = yield tfd.Independent(tfd.Normal(loc=new,\n",
        "                                 scale=scales,  name=f'prior{t}'), 1)\n",
        "\n",
        "    elif structure == 'smoothness':\n",
        "      @tfd.JointDistributionCoroutine\n",
        "      def prior_structure():\n",
        "        previous = yield Root(tfd.Independent(tfd.Normal(loc=initial_mean,\n",
        "                                                    scale=tf.ones_like(initial_mean), name='prior0'), 1))\n",
        "        current = yield Root(tfd.Independent(tfd.Normal(loc=initial_mean,\n",
        "                                                    scale=tf.ones_like(initial_mean), name='prior1'), 1))\n",
        "        for t in range(2, series_len):\n",
        "          new = yield tfd.Independent(tfd.Normal(loc=2 * current - previous,\n",
        "                                                 scale=scales, name=f'prior{t}'), 1)\n",
        "          previous = current\n",
        "          current = new\n",
        "\n",
        "    prior_matching_bijector = tfb.Chain(\n",
        "        get_prior_matching_bijectors_and_event_dims(prior_structure)[-1])\n",
        "\n",
        "    if model_name == 'maf':\n",
        "      flow = get_maf(prior_structure)\n",
        "    elif model_name == 'maf3':\n",
        "      flow_params={'num_flow_layers':3}\n",
        "      flow = get_maf(prior_structure, flow_params)\n",
        "    elif model_name == 'gated_emf_t':\n",
        "      flow = get_gated_emf_t(prior_structure)\n",
        "\n",
        "    flow.log_prob(prior_structure.sample(1))\n",
        "\n",
        "    return flow, prior_matching_bijector"
      ],
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLu-Pwxyr6Ic"
      },
      "source": [
        "@tfd.JointDistributionCoroutine\n",
        "def lorenz_system():\n",
        "  truth = []\n",
        "  innovation_noise = .1\n",
        "  step_size = 0.02\n",
        "  loc = yield Root(tfd.Sample(tfd.Normal(0., 1., name='x_0'), sample_shape=3))\n",
        "  for t in range(1, 30):\n",
        "    x, y, z = tf.unstack(loc, axis=-1)\n",
        "    truth.append(x)\n",
        "    dx = 10 * (y - x)\n",
        "    dy = x * (28 - z) - y\n",
        "    dz = x * y - 8 / 3 * z\n",
        "    delta = tf.stack([dx, dy, dz], axis=-1)\n",
        "    loc = yield tfd.Independent(\n",
        "      tfd.Normal(loc + step_size * delta,\n",
        "                 tf.sqrt(step_size) * innovation_noise, name=f'x_{t}'),\n",
        "      reinterpreted_batch_ndims=1)\n",
        "\n",
        "@tfd.JointDistributionCoroutine\n",
        "def brownian_motion():\n",
        "  new = yield Root(tfd.Normal(loc=0, scale=.1))\n",
        "\n",
        "  for t in range(1, 30):\n",
        "    new = yield tfd.Normal(loc=new, scale=.1)\n",
        "\n",
        "@tfd.JointDistributionCoroutine\n",
        "def ornstein_uhlenbeck():\n",
        "  a = 0.8\n",
        "  new = yield Root(tfd.Normal(loc=0, scale=5.))\n",
        "\n",
        "  for t in range(1, 30):\n",
        "    new = yield tfd.Normal(loc=a*new, scale=.5)\n",
        "\n",
        "def time_series_gen(batch_size, dataset_name):\n",
        "  if dataset_name == 'lorenz':\n",
        "    while True:\n",
        "      yield tf.reshape(tf.transpose(tf.convert_to_tensor(lorenz_system.sample(batch_size)),[1,0,2]), [batch_size, -1])\n",
        "  elif dataset_name == 'brownian':\n",
        "    while True:\n",
        "      yield tf.math.exp(tf.reshape(tf.transpose(tf.convert_to_tensor(brownian_motion.sample(batch_size)),[1,0]), [batch_size, -1]))\n",
        "  elif dataset_name == 'ornstein':\n",
        "    while True:\n",
        "      yield tf.reshape(tf.transpose(tf.convert_to_tensor(ornstein_uhlenbeck.sample(batch_size)),[1,0]), [batch_size, -1])"
      ],
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azVGy4RUhD8X"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEKs76kIgnFv"
      },
      "source": [
        "Modify cell below for training settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBZCjIArtJo6"
      },
      "source": [
        "num_iterations = int(50) # kept low just for demo\n",
        "dataset_name = 'lorenz' # brownian, ornstein, lorenz\n",
        "model_name = 'gated_emf_t' # maf, maf3, gated_emf_t\n",
        "structure = 'continuity' # 'continuity', 'smoothness'\n",
        "lr = 1e-4\n",
        "if dataset_name == 'lorenz':\n",
        "  time_step_dim = 3\n",
        "  series_len = 30\n",
        "\n",
        "elif dataset_name == 'brownian' or dataset_name == 'ornstein':\n",
        "  time_step_dim = 1\n",
        "  series_len = 30"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT9XdkDEy11x"
      },
      "source": [
        "flow, prior_matching_bijector = build_model(model_name, time_step_dim, series_len, structure)\n",
        "dataset = tf.data.Dataset.from_generator(functools.partial(time_series_gen, batch_size=int(100), dataset_name=dataset_name),\n",
        "                                             output_types=tf.float32).map(prior_matching_bijector).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf8Y9xrazK6e"
      },
      "source": [
        "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=lr, decay_steps=5e5)\n",
        "optimizer = tf.optimizers.Adam(learning_rate=lr_decayed_fn)"
      ],
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2IXKU75zPJ7"
      },
      "source": [
        "train_loss_results = []\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "it = 0\n",
        "for x in dataset:\n",
        "\n",
        "  # Optimize the model\n",
        "  loss_value = optimizer_step(flow, x)\n",
        "  epoch_loss_avg.update_state(loss_value)\n",
        "\n",
        "  if it == 0:\n",
        "    best_loss = epoch_loss_avg.result()\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  elif it % 1 == 0:\n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    #print(train_loss_results[-1])\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "  if it >= num_iterations:\n",
        "    break\n",
        "  it += 1"
      ],
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d1RxKbBeztdo",
        "outputId": "03052d8a-63c6-41b1-b92d-94c9317ff46f"
      },
      "source": [
        "plt.plot(train_loss_results)"
      ],
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7178c97450>]"
            ]
          },
          "metadata": {},
          "execution_count": 449
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz593rSvzwSh",
        "outputId": "cbe7a93d-0754-4665-ba69-6ccfd11bbe6d"
      },
      "source": [
        "eval_dataset = tf.data.Dataset.from_generator(functools.partial(time_series_gen, batch_size=int(1e4), dataset_name=dataset_name),\n",
        "                                             output_types=tf.float32).map(prior_matching_bijector)\n",
        "\n",
        "eval_log_prob = -tf.reduce_mean(flow.log_prob(next(iter(eval_dataset))))\n",
        "print(eval_log_prob)"
      ],
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1033.2622, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}